<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title>Algorithms of oppression&mdash;Safiya Umoja Noble</title>
  <style type="text/css">code{white-space: pre;}</style>
  <!DOCTYPE html>
  <html>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link href="../../css/hawthorne_type1_color2.css" rel="stylesheet">
  <style>

  body{
    background-color: lightgrey;
  }

  blockquote p{
      color: #4d4d4d;
  }

  h2,h3,h4,h5 {
      padding: 0 25%;
    }
    h4{
      font-size: 1vw
    }
    h3{
      font-size: 2vw
    }
    h2{
      font-size: 3vw
    }
    h1{
      padding: 0 20%;
      font-size: 4vw
    }
  ul,ol,p {
    background-color: lightgrey;
    font-size:1vw;
    text-align: justify;
    text-justify: inter-word;
    padding: 0 30%
  }

  @media screen and (max-width: 960px) {
    h2,h3,h4,h5 {
      padding: 0 10%;
    }
    h4{
      font-size: 2vw
    }
    h3{
      font-size: 3vw
    }
    h2{
      font-size: 5vw
    }
    h1{
      padding: 0 5%;
      font-size: 7vw
    }
    p{
      font-size: 2vw;
      padding: 0 15%
    }
  }

  @media screen and (max-width: 600px) {
    ul,li,h1,h2,h3,h4,h5 {
      padding: 0 3%;
    }
    h4{
      font-size: 5vw
    }
    h3{
      font-size: 6vw
    }
    h2{
      font-size: 8vw
    }
    h1{
      font-size: 10vw
    }
    p {
      font-size: 4vw;
      padding: 0 5%;
    }
  }
  </style>
  <body>
</head>
<body>
<h1 id="from-algorithms-of-oppression-how-search-engines-reinforce-racism-by-safiya-umoja-noble">From <em>Algorithms of oppression: How search engines reinforce racism</em> by Safiya Umoja Noble</h1>
<h2 id="introduction-the-power-of-algoritms">Introduction: The power of algoritms</h2>
<p>This book is about the power of algorithms in the age of neoliberalism and the ways digital decisions reinforce oppressive social relationships and enact new modes of racial profiling, which I have termed <em>technological redlining</em>. Typically, the practice of redlining has been most often used in real estate and banking circles, creating and deepening inequalities by race, such that, for example, people of color are more likely to pay higher interest rates or premiums just because they are Black or Latino, especially if they live in low-income neighborhoods.
<p>While we often think of terms such as &quot;big data&quot; and &quot;algorithms&quot; as being benign, neutral, or objective, they are anything but. The people who make these decisions hold all types of values, many of which openly promote racism, sexism, and false notions of meritocracy, which is well documented in studies of Silicon Valley and other tech corridors.
<p>Human beings are developing the digital platforms we use, and as I present evidence of the recklessness and lack of regard that is often shown to women and people of color in some of the output of these systems, it will become increasingly difficult for technology companies to separate their systematic and inequitable employment practices, and the far-right ideological bents of some of their employees, from the products they make for the public.
<p>This book is largely concerned with examining the commercial co- optation of Black identities, experiences, and communities in the largest and most powerful technology companies to date, namely, Google. I want us to have broader public conversations about the implications of the artificial intelligentsia for people who are already systematically marginalized and oppressed. I will also provide evidence and argue, ultimately, that large technology monopolies such as Google need to be broken up and regulated, because their consolidated power and cultural influence make competition largely impossible.
<p>My search on the keywords &quot;black girls&quot; yielded <code>HotBlackPussy.com</code> as the first hit.
<p>Hit indeed.
<p>This book was born to highlight cases of such algorithmically driven data failures that are specific to people of color and women and to underscore the structural ways that racism and sexism are fundamental to what I have coined <em>algorithmic oppression</em>. I am writing in the spirit of other critical women of color, such as Latoya Peterson, cofounder of the blog <em>Racialicious</em>, who has opined that racism is the fundamental application program interface (API) of the Internet. This process reflects a corporate logic of either willful neglect or a profit imperative that makes money from racism and sexism. This inquiry is the basis of this book.
<p>I have studied why it is that digital media platforms are resoundingly characterized as “neutral technologies” in the public domain and often, unfortunately, in academia. Stories of “glitches” found in systems do not suggest that the organizing logics of the web could be broken but, rather, that these are occasional one- off moments when something goes terribly wrong with near- perfect systems. We need all the voices to come to the fore and impact public policy on the most unregulated social experiment of our times: the Internet.
<p>The first problem for Google was that its photo application had automatically tagged African Americans as &quot;apes&quot; and &quot;animals.&quot;<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> The second major issue reported by the <em>Post</em> was that Google Maps searches on the word &quot;N*gger&quot;<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> led to a map of the White House during Obama’s presidency.
<p>In each case, Google’s position is that it is not responsible for its algorithm and that problems with the results would be quickly resolved.
<p>In many ways, these cases that I present are specific to the lives and experiences of Black women and girls, people largely understudied by scholars, who remain ever precarious, despite our living in the age of Oprah and Beyoncé in Shondaland.
<p>As a scholar of information and power, I am most interested in communicating a series of processes that have happened, which provide evidence of a constellation of concerns that the public might take up as meaningful and important, particularly as technology impacts social relations and creates unintended consequences that deserve greater attention. Nonetheless, new instances of racism and sexism keep appearing in news and social media, and so I use a variety of these cases to make the point that algorithmic oppression is not just a glitch in the system but, rather, is fundamental to the operating system of the web.
<p>First, we need interdisciplinary research and scholarship in information studies and library and information science that intersects with gender and women’s studies, Black/African American studies, media studies, and communications to better describe and understand how algorithmically driven platforms are situated in intersectional sociohistorical contexts and embedded within social relations. econd, now, more than ever, we need experts in the social sciences and digital humanities to engage in dialogue with activists and organizers, engineers, designers, information technologists, and public-policy makers before blunt artificial-intelligence decision making trumps nuanced human decision making.
<h2 id="a-society-searching">A Society, Searching</h2>
<p>Over the mouths of various women of color were the autosuggestions that reflected the most popular searches that take place on Google Search. The Google Search autosuggestions featured a range of sexist ideas such as the following:
<ul>
<li>Women cannot: drive, be bishops, be trusted, speak in church</li>
<li>Women should not: have rights, vote, work, box</li>
<li>Women should: stay at home, be slaves, be in the kitchen, not speak in church</li>
<li>Women need to: be put in their places, know their place, be controlled, be disciplined</li>
</ul>
<p>The campaign suggests that search is a mirror of users' beliefs and that society still holds a variety of sexist ideas about women. What I find troubling is that the campaign also reinforces the idea that it is not the search engine that is the problem but, rather, the users of search engines who are. While serving as an important and disturbing critique of sexist attitudes, the campaign fails to implicate the algorithms or search engines that drive certain results to the top.
<p>If the majority rules in search engine results, then how might those who are in the minority ever be able to influence or control the way they are represented in a search engine?
<h3 id="google-search-racism-and-sexism-at-the-forefront">Google Search: Racism and Sexism at the Forefront</h3>
<p>My first encounter with racism in search came to me through an experience that pushed me, as a researcher, to explore the mechanisms —both technological and social— that could render the pornification of Black women a top search result, naturalizing Black women as sexual objects so effortlessly.
<p>For whom, then, was this the best information, and who decides? What were the profit and other motives driving this information to the top of the results?
<p>I could see the connection between search results and tropes of African Americans that are as old and endemic to the United States as the history of the country itself.
<p>Critical library and information science scholars have well documented the ways in which some groups are more vulnerable than others to misrepresentation and misclassification.<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a>
<p>The associate professor of sociology at Arizona State University and former president of the Association of Internet Researchers Alex Halavais points to the way that heavily used technological artifacts such as the search engine have become such a normative part of our experience with digital technology and computers that they socialize us into believing that these artifacts must therefore also provide access to credible, accurate information that is depoliticized and neutral
<p>The political nature of search demonstrates how algorithms are a fundamental invention of computer scientists who are human beings —and code is a language full of meaning and applied in varying ways to different types of information.
<p>At the core of my argument is the way in which Google biases search to its own economic interests —for its profitability and to bolster its market dominance at any expense. Many scholars are working to illuminate the ways in which users trade their privacy, personal information, and immaterial labor for &quot;free&quot; tools and services offered by Google (e.g., search engine, Gmail, Google Scholar, YouTube) while the company profits from data mining its users.
<p>However, what is missing from the extant work on Google is an intersectional power analysis that accounts for the ways in which marginalized people are exponentially harmed by Google.
<h3 id="theorizing-search-a-black-feminist-project">Theorizing Search: A Black Feminist Project</h3>
<p>Rather than assert that problematic or racist results are impossible to correct, in the ways that the Google disclaimer suggests<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a>, I believe a feminist lens, coupled with racial awareness about the intersectional aspects of identity, offers new ground and interpretations for understanding the implications of such problematic positions about the benign instrumentality of technologies. It is the persistent normalization of Black people as aberrant and undeserving of human rights and dignity under the banners of public safety, technological innovation, and the emerging creative economy that I am directly challenging by showing the egregious ways that dehumanization is rendered a legitimate free- market technology project.
<p>Where other scholars have problematized Google Search in terms of its lack of neutrality and prioritization of its own commercial interests, my critiques aim to explicitly address racist and sexist bias in search, fueled by neoliberal technology policy over the past thirty years.
<h3 id="black-feminism-as-theoretical-and-methodological-approach">Black Feminism as Theoretical and Methodological Approach</h3>
<p>This is because the public believes that what rises to the top in search is either the most popular or the most credible or both. Yet this does not explain why the word &quot;porn&quot; does not have to be included in keyword searches on &quot;black girls&quot; and other girls and women of color to bring it to the surface as the primary data point about girls and women.
<p>As a theoretical approach, it challenges the dominant research on race and gender, which tends to universalize problems assigned to race or Blackness as &quot;male&quot; (or the problems of men) and organizes gender as primarily conceived through the lenses and experiences of White women, leaving Black women in a precarious and understudied position.
<h3 id="the-importance-of-google">The Importance of Google</h3>
<p>Google, unlike traditional telecommunications companies, has unprecedented access to the collection and provision of data across a variety of platforms in a highly unregulated marketplace and policy environment.
<p>Google Search prioritizes its own interests, and this is something far less visible to the public. Most people surveyed could not tell the difference between paid advertising and &quot;genuine&quot; results.
<h3 id="search-results-as-power">Search Results as Power</h3>
<p>These scholars have shown the problematic ways that women have been represented —as sex objects, incompetent, dependent on men, or underrepresented in the workforce<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a>— and the content and representation of women and girls in search engines is consistent with the kinds of problematic and biased ideas that live in other advertising channels. Of course, this makes sense, because Google Search is in fact an advertising platform, not intended to solely serve as a public information resource in the way that, say, a library might. Google creates advertising algorithms, not information algorithms.
<p>Google, according to its own disclaimer, will only remove pages that are considered unlawful, as is the case in France and Germany, where selling or distributing neo-Nazi materials is prohibited. Without such limits on derogatory, racist, sexist, or homophobic materials, Google allows its algorithm— which is, as we can see, laden with what Diaz calls &quot;sociopolitics&quot;— to stand without debate while protesting its inability to remove pages.
<h3 id="gaming-the-system-optimizing-and-co-opting-results-in-search-engines">Gaming the System: Optimizing and Co-opting Results in Search Engines</h3>
<p>Despite the widespread beliefs in the Internet as a democratic space where people have the power to dynamically participate as equals, the Internet is in fact organized to the benefit of powerful elites<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a>, including corporations that can afford to purchase and redirect searches to their own sites. What is most popular on the Internet is not wholly a matter of what users click on and how websites are hyperlinked— there are a variety of processes at play.
<p>In the case of political information seeking, research has shown how Google directs web traffic to mainstream corporate news conglomerates, which increases their ability to shape the political discourse. Google too is a mediating platform that, at least at one moment in time, in September 2011, allowed the porn industry to take precedence in the representations of Black women and girls over other possibilities among at least eleven and a half billion documents that could have been indexed<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a>.
<p>We must trouble the notion of Google as a public resource, particularly as institutions become more reliant on Google when looking for high-quality, contextualized, and credible information. We need to make more visible the commercial interests that overdetermine what we can find online.
<h3 id="the-enclosure-of-the-public-domain-through-search-engines">The Enclosure of the Public Domain through Search Engines</h3>
<p>Decreases in funding for public information institutions such as libraries and educational institutions and shifts of responsibility to individuals and the private sector have reframed the ways that the public conceives of what can and should be in the public domain. Yet Google Search is conceived of as a public resource, even though it is a multinational advertising company. Beyond the Internet and the control of the network, public information —whether delivered over the web or not— continues to be outsourced to the private sphere, eroding the public information commons that has been a basic tenet of U.S. democracy.
<p>What this critique shows is that the privatization and commercial nature of information has become so normalized that it not only becomes obscured from view but, as a result, is increasingly difficult to critique within the public domain. The Pew Internet and American Life Project corroborates that the public trusts multinational corporations that provide information over the Internet and that there is a low degree of distrust of the privatization of information<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a>.
<h3 id="the-cultural-power-of-algorithms">The Cultural Power of Algorithms</h3>
<p>The former editor of <em>Psychology Today</em> and professor Robert Epstein and Ronald Robertson, the associate director of the American Institute for Behavioral Research and Technology, found in their 2013 study that democracy was at risk because manipulating search rankings could shift voters' preferences, substantially and without their awareness. In their study, they note that the tenor of stories about a candidate in search engine results, whether favorable or unfavorable, dramatically affected the way that people voted. Seventy-five percent of participants were not aware that the search results had been manipulated. The researchers concluded, &quot;The outcomes of real elections —especially tight races— can conceivably be determined by the strategic manipulation of search engine rankings and... that the manipulation can be accomplished without people being aware of it. We speculate that unregulated search engines could pose a serious threat to the democratic system of government.&quot; <a href="#fn9" class="footnoteRef" id="fnref9"><sup>9</sup></a>
<h3 id="losing-control-of-our-images-and-ourselves-in-search">Losing Control of Our Images and Ourselves in Search</h3>
<p>It is well known that traditional media have been rife with negative or stereotypical images of African American/Black people<a href="#fn10" class="footnoteRef" id="fnref10"><sup>10</sup></a>, and the web as the locus of new media is a place where traditional media interests are replicated.
<h3 id="bias-in-search">Bias in Search</h3>
<p>&quot;Traffic Report: How Google Is Squeezing Out Competitors and Muscling Into New Markets,&quot; by ConsumerWatchdog.org's <em>Inside Google</em> (June 2010), details how Google effectively blocks sites that it competes with and prioritizes its own properties to the top of the search pile (YouTube over other video sites, Google Maps over MapQuest, and Google Images over Photobucket and Flickr). The report highlights the process by which Universal Search is not a neutral and therefore universal process but rather a commercial one that moves sites that buy paid advertising to the top of the pile. Amid these practices, the media, buttressed by an FTC investigation<a href="#fn11" class="footnoteRef" id="fnref11"><sup>11</sup></a>, have suggested that algorithms are not at all unethical or harmful because they are free services and Google has the right to run its business in any way it sees fit. Arguably, this is true, so true that the public should be thoroughly informed about the ways that Google biases information —toward largely stereotypic and decontextualized results, at least when it comes to certain groups of people.
<p>Egregious and racist content, content that is highly profitable, proliferates because many tech platforms are interested in attracting the interests and attention of the majority in the United States, not of racialized minorities.
<h3 id="challenging-race--and-gender-neutral-narratives">Challenging Race- and Gender-Neutral Narratives</h3>
<p>Recent research on the male gaze and pornography on the web argue that the Internet is a communications environment that privileges the male, pornographic gaze and marginalizes women as objects<a href="#fn12" class="footnoteRef" id="fnref12"><sup>12</sup></a>. The journalist and producer John Berger's canonical work <em>Ways of Seeing</em>, which describes this objectification in this way: &quot;Women are depicted in a quite different way from men —not because the feminine is different from the masculine— but because the 'ideal' spectator is always assumed to be male and the image of the woman is designed to flatter him.&quot;<a href="#fn13" class="footnoteRef" id="fnref13"><sup>13</sup></a>
<p>Charles Mills, in his canonical work, <em>The Racial Contract</em>, put it this way:
<blockquote>
<p>One could say then, as a general rule, that white misunderstanding, misrepresentation, evasion, and self- deception on matters related to race are among the most pervasive mental phenomena of the past few hundred years, a cognitive and moral economy psychically required for conquest, colonization and enslavement. And these phenomena are in no way accidental, but prescribed by the Racial Contract, which requires a certain schedule of structured blindness and opacities in order to establish and maintain the white polity.90
</blockquote>
<p>It begs the question that if the Internet is a tool for progress and advancement, as has been argued by many media scholars, then cui bono— to whose benefit is it, and who holds the power to shape it?
<h3 id="challenging-cybertopias">Challenging Cybertopias</h3>
<p>Of course, these notions have been consistently challenged, yet they still serve as the basis for beliefs in an ideal of an unmarked humanity —nonracialized, nongendered, and without class distinction— as the final goal of human transcendence. This teleology of the abstracted individual is challenged by the inevitability of such markers and the ways that the individual particularities they signal afford differential realities and struggles, as well as privileges and possibilities. Those who become &quot;marked&quot; by race, gender, or sexuality as other are deviations from the universal human —they are often lauded for &quot;transcending&quot; their markers— while others attempt to &quot;not see color&quot; in a failing quest for colorblindness. We know, of course, that nothing could be further from the truth. Just ask the women of #Gamergate96 and observe the ways that racist, sexist, and homophobic comments and trolling occur every minute of every hour of every day on the web.
<h2 id="searching-for-black-girls">Searching for Black Girls</h2>
<p>Neoliberalism has emerged and served as a framework for developing social and economic policy in the interest of elites, while simultaneously crafting a new worldview: an ideology of individual freedoms that foreground personal creativity, contribution, and participation, as if these engagements are not interconnected to broader labor practices of systemic and structural exclusion. In the case of Google’s history of racist bias in search, no linkages are made between Black Girls Code and remedies to the company's current employment practices and product designs. Indeed, the notion that lack of participation by African Americans in Silicon Valley is framed as a &quot;pipeline issue&quot; posits the lack of hiring Black people as a matter of people unprepared to participate, despite evidence to the contrary. Blacks and Latinos are underemployed despite the increasing numbers graduating from college with degrees in computer science.
<p>Filling the pipeline and holding &quot;future&quot; Black women programmers responsible for solving the problems of racist exclusion and misrepresentation in Silicon Valley or in biased product development is not the answer.
<p>This is only exacerbated by framing the problems as &quot;pipeline&quot; issues instead of as an issue of racism and sexism, which extends from employment practices to product design. &quot;Black girls need to learn how to code&quot; is an excuse for not addressing the persistent marginalization of Black women in Silicon Valley.
<h3 id="who-is-responsible-for-the-results">Who Is Responsible for the Results?</h3>
<p>As a result of the lack of African Americans and people with deeper knowledge of the sordid history of racism and sexism working in Silicon Valley, products are designed with a lack of careful analysis about their potential impact on a diverse array of people.
<p>Not only are African Americans underemployed at Google, Facebook, Snapchat, and other popular technology companies as computer programmers, but jobs that could employ the expertise of people who understand the ramifications of racist and sexist stereotyping and misrepresentation and that require undergraduate and advanced degrees in ethnic, Black / African American, women and gender, American Indian, or Asian American studies are nonexistent.
<p>I can say that when I teach engineering students at UCLA about the histories of racial stereotyping in the U.S. and how these are encoded in computer programming projects, my students leave the class stunned that no one has ever spoken of these things in their courses.
<p>To understand representations of race and gender in new media, it is necessary to draw on research about how race is constituted as a social, economic, and political hierarchy based on racial categories, how people are racialized, how this can shift over time without much disruption to the hierarchical order, and how White American identity functions as an invisible &quot;norm&quot; or &quot;nothingness&quot; on which all others are made aberrant.
<p>For Treitler, theories of racial formation are less salient —it does not matter whether one believes in race or not, because it is a governing paradigm that structures social logics. Race, then, is a hierarchical system of privilege and power that is meted out to people on the basis of perceived phenotype and heritage, and ethnic groups work within the already existent racial hierarchy to achieve more power, often at the expense of other ethnic groups.
<p>Google reported these search results as an anomaly, beyond its control, to which I responded again, &quot;If Google isn't responsible for its algorithm, then who is?&quot;
<p>What we know about Google's responses to racial stereotyping in its products is that it typically denies responsibility or intent to harm, but then it is able to &quot;tweak&quot; or &quot;fix&quot; these aberrations or &quot;glitches&quot; in its systems. What we need to ask is why and how we get these stereotypes in the first place and what the attendant consequences of racial and gender stereotyping do in terms of public harm for people who are the targets of such misrepresentation.
<p>Understanding technological racialization as a particular form of algorithmic oppression allows us to use it as an important framework in which to critique the discourse of the Internet as a democratic landscape and to deploy alternative thinking about the practices instantiated within commercial web search.
<p>In this work, I am claiming that you cannot have social justice and a politics of recognition without an acknowledgment of how power —often exercised simultaneously through White supremacy and sexism— can skew the delivery of credible and representative information. Because Black communities live in material conditions that are structured physically and spatially in the context of a freedom struggle for recognition and resources, the privately controlled Internet portals that function as a public space for making sense of the distribution of resources, including identity-based information, have to be interrogated thoroughly.
<p>Google's enviable position as the monopoly leader in the provision of information has allowed its organization of information and customization to be driven by its economic imperatives and has influenced broad swaths of society to see it as the creator and keeper of information culture online, which I am arguing is another form of American imperialism that manifests itself as a &quot;gatekeeper&quot;<a href="#fn14" class="footnoteRef" id="fnref14"><sup>14</sup></a> on the web. It is time for the monopoly to be broken apart and for public search alternatives to be created.
<h3 id="how-pornification-happened-to-black-girls-in-the-search-engine">How Pornification Happened to &quot;Black Girls&quot; in the Search Engine</h3>
<p>The porn industry is one of the most well-informed industries with sophisticated usage of SEO [search engine optimization]. A former SEO director for FreePorn.com has blogged extensively on how to elude Google and maximize the ability to show up in the first page of search results <a href="#fn15" class="footnoteRef" id="fnref15"><sup>15</sup></a>.
<p>The U.S. pornography industry is powerful and has the capital to purchase any keywords —and identities— it wants.
<p>These search engine results for women whose identities are already maligned in the media, such as Black women and girls<a href="#fn16" class="footnoteRef" id="fnref16"><sup>16</sup></a>, only further debase and erode efforts for social, political, and economic recognition and justice<a href="#fn17" class="footnoteRef" id="fnref17"><sup>17</sup></a>. These practices instantiate limited, negative portrayals of people of color in the media<a href="#fn18" class="footnoteRef" id="fnref18"><sup>18</sup></a> —a defining and normative feature of American racism<a href="#fn19" class="footnoteRef" id="fnref19"><sup>19</sup></a>. However, the web reflects a set of commercial and advertising practices that bias particular ideas. Those industries and interests that are powerful, influential, or highly capitalized are often prioritized to the detriment of others and are able to control the bias on their terms.
<h3 id="blackness-in-the-neoliberal-marketplace">Blackness in the Neoliberal Marketplace</h3>
<p>Many people say to me, &quot;But tech companies don't mean to be racist; that’s not their intent.&quot; Intent is not particularly important. Outcomes and results are important.
<blockquote>
<p>Because most users view themselves, and their uses of the Net, as apolitical, hegemonic discourses tend to be reproduced unintentionally... Whatever blatant perspectives mired in racism, sexism, or other equally unpalatable ideologies pervade society at large, they are carried into, and reproduced within, cyberspace.<a href="#fn20" class="footnoteRef" id="fnref20"><sup>20</sup></a>
</blockquote>
<p>&quot;The rhetorical narrative of 'Whiteness as normality' configures information technologies and software designs&quot; and is reproduced through digital technologies.
<blockquote>
<p>These practices neatly recreate social dynamics online that mirror offline patterns of racial interaction by marginalizing women and people of color.<a href="#fn21" class="footnoteRef" id="fnref21"><sup>21</sup></a>
</blockquote>
<h3 id="black-girls-as-commodity-object">Black Girls as Commodity Object</h3>
<p>Part of the socialization of Black women as sexual object is derived from historical constructions of African women living under systems of enslavement and economic dependency and exploitation —systems that included the normalization of rape and conquest of Black bodies and the invention of fictions about Black women<a href="#fn22" class="footnoteRef" id="fnref22"><sup>22</sup></a>.
<p>I argue that these segmented social structures persist at a historical moment when Black women and children are part of the permanent underclass and represent the greatest proportion of citizens living in poverty<a href="#fn23" class="footnoteRef" id="fnref23"><sup>23</sup></a>.
<h3 id="historical-categorizations-of-racial-identity-old-traditions-never-die">Historical Categorizations of Racial Identity: Old Traditions Never Die</h3>
<p>It highlights the two main narratives that have continued to besiege Black women: the exotic other, the Jezebel whore; and the pathetic other, the Mammy<a href="#fn24" class="footnoteRef" id="fnref24"><sup>24</sup></a>. Notably, the pathetic other is too ugly, too stupid, and too different to elicit sexual attraction from reasonable men; instead, she is a source of pity, laughter, and derision.
<p>Jezebel is now known as the video vixen, the &quot;ho,&quot; the &quot;around the way girl,&quot; the porn star —and she remains an important part of the spectacle that justifies the second-class citizenship of Black women<a href="#fn25" class="footnoteRef" id="fnref25"><sup>25</sup></a>. &quot;Black women&quot; searches offer sites on &quot;angry Black women&quot; and articles on &quot;why Black women are less attractive.&quot; These narratives of the exotic or pathetic Black woman, rooted in psychologically damaging stereotypes of the Jezebel<a href="#fn26" class="footnoteRef" id="fnref26"><sup>26</sup></a>, Sapphire, and Mammy<a href="#fn27" class="footnoteRef" id="fnref27"><sup>27</sup></a>, only exacerbate the pornographic imagery that represents Black girls, who are largely presented in one of these ways.
<h3 id="reading-the-pornographic-representation">Reading the Pornographic Representation</h3>
<p>Some people argue that pornography has been understudied given its commercial viability and persistence<a href="#fn28" class="footnoteRef" id="fnref28"><sup>28</sup></a>.
<blockquote>
<p>The relative invisibility of commercial pornography in the field has more to do with cultural hierarchies and questions of taste: as a popular genre, pornography has considerably low cultural status as that which, according to various US court decisions, lacks in social, cultural, or artistic value. Furthermore, the relatively sparse attention to porn is telling of an attachment to representations and exchanges considered novel over more familiar and predictable ones.<a href="#fn29" class="footnoteRef" id="fnref29"><sup>29</sup></a>
</blockquote>
<p>As such, Black women and girls are both understudied by scholars and also associated with “low culture” forms of representation<a href="#fn30" class="footnoteRef" id="fnref30"><sup>30</sup></a>. There is a robust political economy of pornography, which is an important site of commerce and technological innovation that includes file-sharing networks, video streaming, e-commerce and payment processing, data compression, search, and transmission <a href="#fn31" class="footnoteRef" id="fnref31"><sup>31</sup></a>.
<h3 id="what-we-find-is-meaningful">What We Find Is Meaningful</h3>
<p>Research shows how stereotypical depictions of women and minorities in advertising impact the behavior of those who consume it<a href="#fn32" class="footnoteRef" id="fnref32"><sup>32</sup></a>. Therefore, it is necessary to cast a deeper look into the effects of the content and trace the kinds of hegemonic narratives that situate these results.
<p>Institutional relations predicated on gender and race situate women and people of color outside the power systems from which technology arises. This is how colorblind ideology is mechanized in Silicon Valley: through denial of the existence of both racial orders and contributions from non-Whites.
<p>The value of this exploration is in showing how gender and race are socially constructed and mutually constituted through science and technology. The very notion that technologies are neutral must be directly challenged as a misnomer.
<h2 id="searching-for-people-and-communities">Searching for People and Communities</h2>
<p>What is compelling about the alleged information that Roof accessed is how his search terms did not lead him to Federal Bureau of Investigation (FBI) crime statistics on violence in the United States, which point to how crime against White Americans is largely an intraracial phenomenon. Most violence against White Americans is committed by White Americans, as most violence against African Americans is largely committed by other African Americans. White-on-White crime is the number-one cause of homicides against White Americans, as violent crime is largely a matter of perpetration by proximity to those who are demographically similar to the victim<a href="#fn33" class="footnoteRef" id="fnref33"><sup>33</sup></a>. Homicides across racial lines do not nearly happen in the ways White supremacist organizations purport. A search on the phrase “black on white crimes” does not lead to any experts on race or to any universities, libraries, books, or articles about the history of race in the United States and the invention of racist myths in service of White supremacy, such as &quot;black on white crime.&quot;
<p>What we need is a way to reframe, reimagine, relearn, and remember the struggle for racial and social justice and to see how information online in ranking systems can also impact behavior and thinking offline. There is no federal, state, or local regulation of the psychological impact of the Internet, yet big- data analytics and algorithms derived from it hold so much power in overdetermining decisions. Algorithms that rank and prioritize for profits compromise our ability to engage with complicated ideas. There is no counterposition, nor is there a disclaimer or framework for contextualizing what we get. Had Dylann Roof asked an expert on the rhetoric of the CCC and hate groups in the U.S., such as the Southern Poverty Law Center, he would have found a rich, detailed history of how White supremacist organizations work to undermine democracy and civil rights, and we can only hope that education would have had an impact on his choices.
<h2 id="searching-for-protections-from-search-engines">Searching for Protections from Search Engines</h2>
<p>What does it mean that one’s past is always determining one’s future because the Internet never forgets?
<h3 id="on-the-right-to-be-forgotten">On the Right to Be Forgotten</h3>
<p>I am not talking solely about the harmful effects of search results for groups of people. I am also concerned about the logic and harm caused by our reliance on large corporations to feed us information, information that ultimately leads us somewhere, often to places unexpected and unintended. In the case of the web results, this means communicating erroneous, false, or downright private information that one would otherwise not want perceived as the “official record” of the self on Google, the effects of which can be devastating.
<p>At a time when state funding for public goods such as universities, schools, libraries, archives, and other important memory institutions is in decline in the U.S., private corporations are providing products, services, and financing on their behalf. With these trade- offs comes an exercising of greater control over the information, which is deeply consequential for those who are already systematically oppressed, as noted by the many scholars I have discussed in this book.
<p>Our worst moments are also for sale, as police database mug shots are the fodder of online platforms that feature pictures of people who have been arrested. This is a practice that disproportionately impacts people of color, particularly African Americans, who are overarrested in the United States for crimes that they may not be convicted of in court. New platforms such as Mugshots.com and UnpublishArrest.com are services that promise, for a fee of $399 (one arrest) up to $1,799 (for five arrests), to remove mug shots from the Mugshots.com database across all major search engines.
<p>On July 14, 2015, the Guardian reported that &quot;less than 5% of nearly 220,000 individual requests made to Google to selectively remove links to online information concern criminals, politicians and high- profile public figures... with more than 95% of requests coming from everyday members of the public.&quot;<a href="#fn34" class="footnoteRef" id="fnref34"><sup>34</sup></a> What is critical to this new revelation is that previously Google’s statements about the nature of “right to be forgotten” requests have been exaggerated or unknown because delisting information from its records has not been transparent.
<p>Robertson raises the important ethical issues, as have many other researchers, about what should be digitized and put on the open web and what belongs to communities with shared values, to be shared within a community: In talking to some queer pornographers, I’ve learned that some of their former models are now elementary school teachers, clergy, professors, child care workers, lawyers, mechanics, health care professionals, bus drivers and librarians. We live and work in a society that is homophobic and not sex positive.
<p>These are the kinds of issues facing information workers, from the digitization of indigenous knowledge from all corners of the earth that are not intended for mass public consumption, to individual representations that move beyond the control of the subject. We cannot ignore the long-term consequences of what it means to have everything subject to public scrutiny, out of context, out of control.
<h2 id="the-future-of-knowledge-in-the-public">The Future of Knowledge in the Public</h2>
<h3 id="illegal-alien-revisited">&quot;Illegal Alien&quot; Revisited</h3>
<p>The struggle over reclassifying undocumented immigrants was part of a long history of naming members of society as problem people. In many ways, this effort to eliminate &quot;illegal alien&quot; was similar to the ways that Jewish people were once classified by the Library of Congress as the &quot;Jewish question,&quot; later to be reclassified in 1984 as &quot;Jews,&quot; and Asian Americans were once classified as the &quot;Yellow Peril.&quot;<a href="#fn35" class="footnoteRef" id="fnref35"><sup>35</sup></a> Control over identity is political and often a matter of public policy.
<h3 id="problems-in-classifying-people">Problems in Classifying People</h3>
<p>The idea of classification as a social construct is not new.
<p>Traditional library and information science (LIS) organization sys- tems such as subject cataloging and classification are an important part of understanding the landscape of how information science has inherited and continues biased practices in current system designs, especially on the web.
<h3 id="a-short-history-of-misrepresentation-in-classifying-people">A Short History of Misrepresentation in Classifying People</h3>
<p>In order to understand how racial and gender representations in Google Search express the same traditional bias that exists in other organizational systems, an overview of how women and non- Whites have been historically represented in information categorization environments is in order. The issue of misrepresentations of women and people of color in classification systems has been significantly critiqued<a href="#fn36" class="footnoteRef" id="fnref36"><sup>36</sup></a>.
<p>It is here that the context and point of view of library and information science professionals who are responsible for framing people and communities as &quot;problems&quot; and &quot;questions&quot; is important. By examining the ways that Black people specifically have been constructed in the knowledge schemes, the African American studies professor and philosopher Cornel West aptly describes the positionality of how this community is depicted in the West:
<blockquote>
<p>Black people as a problem-people rather than people with problems; black people as abstractions and objects rather than individuals and persons; black and white worlds divided by a thick wall (or a &quot;Veil&quot;)...; black rage, anger, and fury concealed in order to assuage white fear and anxiety; and black people rootless and homeless on a perennial journey to discover who they are in a society content to see blacks remain the permanent underdog<a href="#fn37" class="footnoteRef" id="fnref37"><sup>37</sup></a>.
</blockquote>
<h3 id="reproducing-social-relations-through-information-technologies">Reproducing Social Relations through Information Technologies</h3>
<p>What we need are public search engine alternatives, united with public-interest journalism and librarianship, to ensure that the public has access to the highest quality information available.
<h2 id="the-future-of-information-culture">The Future of Information Culture</h2>
<p>An increasingly de- and unregulated commercially driven Internet raises significant issues about how information is accessed and made available. This is exacerbated by the gamification of news and headlines, as Nicole Cohen has documented in her ethnography of journalists who write for online news outlets. In her book <em>Writers' Rights: Freelance Journalism in a Digital Age</em>, she documents the increasing tensions between journalists and commercial news media organizations<a href="#fn38" class="footnoteRef" id="fnref38"><sup>38</sup></a>.
<p>Organizations such as FreePress.org are showing how the rise of advertising and commercial interests have bankrupted the quality and content of journalism, heretofore considered a fundamental and necessary component of a democratic society.
<p>Media stereotypes, which include search engine results, not only mask the unequal access to social, political, and economic life in the United States as broken down by race, gender, and sexuality; they maintain it<a href="#fn39" class="footnoteRef" id="fnref39"><sup>39</sup></a>.
<p>Unlike the vetting of journalists and librarians, who are entrusted to fact check and curate information for the public according to professional codes of ethics, the legitimacy of websites' ranking and credibility is simply taken for granted. The take-home message is that, when it comes to online commercial search engines, it is no longer enough to simply share news and education on the web; we must ask ourselves how the things we want to share are found and how the things we find have appeared.
<h3 id="a-monopoly-on-information">A Monopoly on Information</h3>
<p>Commercial search engines, at present, have been able to hide behind disclaimers asserting that they are not responsible for what happens in their search engine technologies.
<p>During the congressional hearings that led to the Federal Trade Commission investigation of Google, the reporter Matthew Ingram suggested in a September 2011 article that &quot;it would be hard for anyone to prove that the company's free services have injured consumers.&quot;<a href="#fn40" class="footnoteRef" id="fnref40"><sup>40</sup></a> But Ingram is arguably defining “injury” a little too narrowly.
<h3 id="the-web-as-a-source-of-opportunity">The Web as a Source of Opportunity</h3>
<p>However true the disparities between Whites and non- Whites or men and women in the traditional articulations of the digital divide, often missing from this discourse is the framework of power relations that precipitate such unequal access to social, economic, and educational resources.<a href="#fn41" class="footnoteRef" id="fnref41"><sup>41</sup></a> Thus, the context for discussing the digital divide in the U.S. is too narrow a framework that focuses on the skills and capabilities of people of color and women, rather than questioning the historical and cultural development of science and technology and representations prioritized through digital technologies, as well as the uneven and exploitive global distribution of resources and labor in the information and communication ecosystem.
<p>I raise this issue because research on the global digital divide, and Google's role in it<a href="#fn42" class="footnoteRef" id="fnref42"><sup>42</sup></a>, must continue to expand to include a look at the ways that Black people in the U.S. and abroad are participating and, in the case of the United States, <em>not</em> participating to a significant degree in information and communication technology industries<a href="#fn43" class="footnoteRef" id="fnref43"><sup>43</sup></a>. This makes calls for &quot;prosumer&quot; participation<a href="#fn44" class="footnoteRef" id="fnref44"><sup>44</sup></a>, as a way of conceptualizing how Black people can move beyond being simple consumers of digital technologies to producers of technological output, a far more complex discussion.
<p>From claims of Twitter's racist trolling that drives people from its platform<a href="#fn45" class="footnoteRef" id="fnref45"><sup>45</sup></a> to charges that Airbnb's owners openly discriminate against African Americans who rent their homes<a href="#fn46" class="footnoteRef" id="fnref46"><sup>46</sup></a> to racial profiling at Apple stores in Australia<a href="#fn47" class="footnoteRef" id="fnref47"><sup>47</sup></a> and Snapchat's racist filters,<a href="#fn48" class="footnoteRef" id="fnref48"><sup>48</sup></a> there is no shortage of projects to take on in sophisticated ways by people far more qualified than untrained computer engineers, whom, through no fault of their own, are underexposed to the critical thinking and learning about history and culture afforded by the social sciences and humanities in most colleges of engineering nationwide. The lack of a diverse and critically minded workforce on issues of race and gender in Silicon Valley impacts its intellectual output.
<p>Meanwhile, the onus for change is placed on the backs of Black people, and Black women in the United States in particular, to play a more meaningful role in the production of new images and ideas about Black people by learning to code, as if that alone could shift the tide of Silicon Valley's vast exclusionary practices in its products and hiring. Michele Wallace, notes the crisis in lack of management, design, and control that Black people have over the production of commercial culture. She states that under these conditions, Black people will be &quot;perpetual objects of contemplation, contempt, derision, appropriation, and marginalization.&quot;<a href="#fn49" class="footnoteRef" id="fnref49"><sup>49</sup></a>
<h3 id="social-inequality-will-not-be-solved-by-an-app">Social Inequality Will Not Be Solved by an App</h3>
<p>An app will not save us. We will not sort out social inequality lying in bed staring at smartphones. It will not stem from simply sending emails to people in power, one person at a time. These proindividual, anticommunity ideologies have been central to the antidemocratic, anti-affirmative-action, antiwelfare, antichoice, and antirace discourses that place culpability for individual failure on moral failings of the individual, not policy decisions and social systems<a href="#fn50" class="footnoteRef" id="fnref50"><sup>50</sup></a>.
<p>In the midst of the changing social and legal environment, inventions of terms and ideologies of “colorblindness” disingenuously purport a more humane and nonracist worldview<a href="#fn51" class="footnoteRef" id="fnref51"><sup>51</sup></a>. This is exacerbated by celebrations of multiculturalism and diversity that obscure structural and social oppression in fields such as education and information sciences, which are shaping technological practices<a href="#fn52" class="footnoteRef" id="fnref52"><sup>52</sup></a>. Research by Sharon Tettegah shows that people invested in colorblindness are also less empathetic toward others<a href="#fn53" class="footnoteRef" id="fnref53"><sup>53</sup></a>. Making race the problem of those who are racially objectified, particularly when seeking remedy from discriminatory practices, obscures the role of government and the public in solving systemic issues<a href="#fn54" class="footnoteRef" id="fnref54"><sup>54</sup></a>.
<p>Silicon Valley executives, as previously noted, revel in their embrace of colorblindness as if it is an asset and not a proven liability. In the midst of reenergizing the effort to connect every American and to stimulate new economic markets and innovations that the Internet and global communications infrastructures will afford, the real lives of those who are on the margin are being reengineered with new terms and ideologies that make a discussion about such conditions problematic, if not impossible, and that place the onus of discriminatory actions on the individual rather than situating problems affecting racialized groups in social structures<a href="#fn55" class="footnoteRef" id="fnref55"><sup>55</sup></a>.
<p>Formulations of postracialism presume that racial disparities no longer exist, a context within which the colorblind ideology finds momentum<a href="#fn56" class="footnoteRef" id="fnref56"><sup>56</sup></a>.
<p>I do not think it a coincidence that when women and people of color are finally given opportunity to participate in limited spheres of decision making in society, computers are simultaneously celebrated as a more optimal choice for making social decisions. The rise of big-data optimism is here, and if ever there were a time when politicians, industry leaders, and academics were enamored with artificial intelligence as a superior approach to sense- making, it is now. This should be a wake-up call for people living in the margins, and people aligned with them, to engage in thinking through the interventions we need.
<h2 id="conclusion-algorithms-of-oppression">Conclusion: Algorithms of Oppression</h2>
<p>I have shined a light on the way that algorithms are value- laden propositions worthy of our interrogation. I have tried to show how traditional media misrepresentations have been instantiated in digital platforms such as search engines and that search itself has been interwoven into the fabric of American culture. Algorithms are, and will continue to be, contextually relevant and loaded with power.
<h3 id="algorithms-and-invisibility-my-interview-with-kandis">Algorithms and Invisibility: My Interview with Kandis</h3>
<p>The framing of web content and ownership of web URLs as &quot;property&quot; afforded private protections is of consequence for individuals, as noted in Jessie Daniels's aforementioned work, which documents the misrepresentation of Dr. Martin Luther King Jr. at the site martinlutherking.org, a cloaked website managed by neo- Nazis and White supremacists at Stormfront<a href="#fn57" class="footnoteRef" id="fnref57"><sup>57</sup></a>. Private ownership of identity on the web is a matter of who can pay and who lines up quickly enough to purchase identity markers that establish a type of official record about a person or a group of people. Indeed, anyone can own anyone else’s identity in the current digital landscape. The right to control over group and personal identity and memory must become a matter of concern for archivists, librarians, and information workers, and a matter of internet regulation and public policy.
<p>In concluding this book, I want to extend an example beyond Google to look closely at the consequences of the lack of identity control on another platform: Yelp.
<blockquote>
<p>So, when I discovered Yelp and it’s alleged benefits —because I don’t think it really benefited me— I was forced to participate in Yelp.
</blockquote>
<p>I asked what that participation with Yelp was like.
<blockquote>
<p>They tell you that everything is free, like they are doing a community service, but later on, it’s basically pay to play. They call on a regular basis to get you to spend a few hundred dollars a month to advertise with them, and if you don't, they are going to push you further down their pile. I can be sitting in my chair searching for myself and not find me or find me ten pages later. I can type in every keyword, like &quot;African American&quot;, &quot;Black&quot;, &quot;relaxer&quot;, &quot;natural&quot;, as keywords, and White businesses, White hairdressers, or White salons would clearly come up before me —along with people who have not been in business as long as me. I think they need to put in how long someone has been in business in that algorithm, because I don’t think it’s fair that people who are brand new are popping up before those of us who may or may not be on the Internet but have more experience and are more established.
<p>And another thing, Black people don't &quot;check in&quot; and let people know where they’re at when they sit in my chair. They already feel like they are being hunted; they aren't going to tell The Man where they are. I have reviews from real clients that they put into a filter because it doesn't meet their requirements of how they think someone should review me.
<p>They control the algorithm, which controls who can write the reviews. All this has a major influence on where you’re placed on the list. You hope and pray that your customers, who may be from a different generation or culture, will participate in their construct. It just isn’t as random as one may think.
<p>There is no algorithm that can replace human dignity. They created a system that simulates a value, based on their own algorithm, so Yelp can be the number-one beneficiary. When companies like Yelp shake the tree for low-hanging fruit, this affects mostly small businesses and the livelihoods of real people who will never work for corporate America. The key is to be independent of these companies, because they never stop. They have new goals, and they come back with new visions. And it's not like a real contract where you can argue and negotiate. The scale is unbalanced; you can’t negotiate.
</blockquote>
<p>She has so little ability to impact the algorithm, and when she tries, the company subverts her ability to be racially and gender recognized —a type of recognition that is essential to her success as a business owner. The attempts at implementing a colorblind algorithm in lieu of human decision making has tremendous consequences. In the case of Kandis, what the algorithm says and refuses to say about her identity and the identity of her customers has real social and economic impact.
<h3 id="imagining-alternatives-toward-public-noncommercial-search">Imagining Alternatives: Toward Public Noncommercial Search</h3>
<p>What is needed is a decoupling of advertising and commercial interests from the ability to access high-quality information on the Internet, especially given its increasing prominence as the common medium in the United States.
<hr />
<h2 id="references">References</h2>
<ul>
<li>Barzilai-Nahon, K. (2006). Gatekeepers, Virtual Communities and the Gated: Multidimensional Tensions in Cyberspace. <em>International Journal of Communications, Law and Policy</em>, 11, 1–28.</li>
<li>Bell, D. (1992). <em>Faces at the Bottom of the Well</em>. New York: Basic Books.</li>
<li>Berger, J. (1972). <em>Ways of Seeing</em>. London: British Broadcasting Corporation and Penguin Books.</li>
<li>Berman, S. (1971). <em>Prejudices and Antipathies: A Tract on the LC Subject Heads Concerning People</em>. Metuchen, NJ: Scarecrow.</li>
<li>Brock, A. (2011). Beyond the Pale: The Blackbird Web Browser's Critical Reception. <em>New Media and Society</em> 13(7), 1085–1103.</li>
<li>Brown, M. (2003). <em>Whitewashing Race: The Myth of a Color-Blind Society</em>. Berkeley: University of California Press.</li>
<li>Burdman, P. (2008). Race-Blind Admissions. Retrieved from <code>www.alumni.berkeley.edu</code>.</li>
<li>Cohen, N. (2016). <em>Writers' Rights: Freelance Journalists in a Digital Age</em>. Montreal: McGill-Queen’s University Press.</li>
<li>Corea, A. (1993). Racism and the American Way of Media. In A. Alexander and J. Hanson (Eds.), <em>Taking Sides: Clashing Views on Controversial Issues in Mass Media and Society</em>, 24– 31. Guilford, CT: Dushkin.</li>
<li>Courtney, A., and Whipple, T. (1983). <em>Sex Stereotyping in Advertising</em>. Lexington, MA: D.C. Heath.</li>
<li>Crenshaw, K. W. (1991). Mapping the Margins: Intersectionality, Identity Politics, and Violence against Women of Color. <em>Stanford Law Review</em>, 43(6), 1241–1299.</li>
<li>Daniels, J. (2008). Race, Civil Rights, and Hate Speech in the Digital Era. In Anna Everett (Ed.), <em>Learning Race and Ethnicity: Youth and Digital Media</em>, 129–154. Cambridge, MA: MIT Press.</li>
<li>Dates, J. (1990). A War of Images. In J. Dates and W. Barlow (Eds.), <em>Split Images: African Americans in the Mass Media</em>, 1–25. Washington, DC: Howard University Press.</li>
<li>Davis, A. (1972). Reflections on the Black Woman's Role in the Community of Slaves. <em>Massachusetts Review</em>, 13(1–2), 81–100.</li>
<li>Delgado, R., and Stefancic, J. (1999). <em>Critical Race Theory: The Cutting Edge</em>. Philadelphia: Temple University Press.</li>
<li>Dewey, C. (2015, May 20). Google Maps' White House Glitch, Flickr Auto-tag, and the Case of the Racist Algorithm. <em>Washington Post</em>. Retrieved from <code>www.washington-post.com</code>.</li>
<li>Dines, G. (2010). <em>Pornland: How Porn Has Hijacked Our Sexuality</em>. Boston: Beacon.</li>
<li>Eddie, R., and Prigg, M. (2015, November 13). &quot;This Does Not Represent Our Values&quot;: Tim Cook Addresses Racism Claims after Seven Black Students Are Ejected from an Apple Store and Told They &quot;Might Steal Something.&quot; <em>Daily Mail</em>. Retrieved from <code>www.dailymail.co.uk</code>.</li>
<li>Epstein, R., and Robertson, R. (2015). The Search Engine Manipulation Effect (SEME) and Its Possible Impact on the Outcomes of Elections. <em>PNAS</em>, 112(33), E4512–E4521.</li>
<li>Fallows, D. (2005, January 23). Search Engine Users. Pew Research Center. Retrieved from <code>www.pewinternet.org</code>.</li>
<li>Furner, J. (2007). Dewey Deracialized: A Critical Race-Theoretic Perspective. <em>Knowledge Organization</em>, 34, 144– 168.</li>
<li>Glusac, E. (2016, June 21). As Airbnb Grows, So Do Claims of Discrimination. <em>New York Times</em>. Retrieved from <code>www.nytimes.com</code>.</li>
<li>Gulli, A., and Signorini, A. (2005). The Indexable Web Is More than 11.5 Billion Pages. In <em>Proceedings of the WWW2005</em>. Retrieved from <code>http://www2005.org</code>.</li>
<li>Halavais, A. (2009). <em>Search Engine Society</em>. Cambridge, MA: Polity.</li>
<li>Harris-Perry, M. V. (2011). <em>Sister Citizen: Shame, Stereotypes, and Black Women in America</em>. New Haven, CT: Yale University Press.</li>
<li>Heider, D., and Harp, D. (2002). New Hope or Old Power: Democracy, Pornography and the Internet. <em>Howard Journal of Communications</em>, 13(4), 285–299.</li>
<li>Hindman, M. S. (2009). The Myth of Digital Democracy. Princeton, NJ: Princeton University Press.</li>
<li>hooks, b. (1992). <em>Black Looks: Race and Representation</em>. Boston: South End.</li>
<li>Ingram, M. (2011, September 22). A Google Monopoly Isn't the Point. <em>GigaOM</em>. Retrieved from <code>www.gigaom.com</code>.</li>
<li>Jennings, J., Geis, F. L., and Brown, V. (1980). Influence of Television Commercials on Women's Self-Confidence and Independent Judgment. <em>Journal of Personality and Social Psychology</em>, 38(2), 203–210. <code>doi:10.1037/0022–3514.38.2.203</code>.</li>
<li>Jensen, R. (2005). <em>The Heart of Whiteness: Confronting Race, Racism, and White Privilege</em>. San Francisco: City Lights.</li>
<li>Kenrick, D. T., Gutierres, S. E., and Goldberg, L. L. (1989). Influence of Popular Erotica on Judgments of Strangers and Mates. <em>Journal of Experimental Social Psychology</em>, 25, 159–167.</li>
<li>Ladson-Billings, G. (2009). &quot;Who You Callin' Nappy- Headed?&quot; A Critical Race Theory Look at the Construction of Black Women. <em>Race, Ethnicity and Education</em>, 12(1), 87–99.</li>
<li>Mastro, D. E., and Tropp, L. R. (2004). The Effects of Interracial Contact, Attitudes, and Stereotypical Portrayals on Evaluations of Black Television Sitcom Characters. <em>Communication Research Reports</em>, 21, 119– 129.</li>
<li>Meyer, R. (2016, July 21). Twitter's Famous Racist Problem. <em>Atlantic</em>. Retrieved from <code>www.theatlantic.com</code>.</li>
<li>Miller-Young, M. (2005). Sexy and Smart: Black Women and the Politics of Self-Authorship in Netporn. In K. Jacobs, M. Janssen, and M. Pasquinelli (Eds.), <em>C'lick Me: A Netporn Studies Reader</em>, 205–216. Amsterdam: Institute of Network Cultures.</li>
<li>Mosher, A. (2016, August 10). Snapchat under Fire for &quot;Yellowface&quot; Filter. USA Today. Retrieved from <code>www.usatoday.com</code>.</li>
<li>Neville, H., Coleman, N., Falconer, J. W., and Holmes, D. (2005). Color-Blind Racial Ideology and Psychological False Consciousness among African Americans. <em>Journal of Black Psychology</em>, 31(1), 27–45. <code>doi:10.1177/0095798404268287</code>.</li>
<li>Olson, H. A. (1998). Mapping beyond Dewey’s Boundaries: Constructing Classificatory Space for Marginalized Knowledge Domains. In G. C. Bowker and S. L. Star (Eds.), <em>How Classifications Work: Problems and Challenges in an Electronic Age</em>, special issue, <em>Library Trends</em>, 47(2), 233–254.</li>
<li>Paasonen, S. (2010). Trouble with the Commercial: Internets Theorised and Used. In J. Hunsinger, L. Klastrup, and M. Allen (Eds.), <em>The International Handbook of Internet Research</em>, 411–422. Dordrecht, The Netherlands: Springer.</li>
<li>Paasonen, S. (2011). Revisiting Cyberfeminism. <em>Communications: European Journal of Communication Research</em>, 36(3), 335–352.</li>
<li>Pawley, C. (2006). Unequal Legacies: Race and Multiculturalism in the LIS Curriculum. <em>Library Quarterly</em>, 76(2), 149–169.</li>
<li>Purcell, K., Brenner, J., and Rainie, L. (2012, March 9). Search Engine Use 2012. Pew Research Center. Retrieved from <code>www.pewinternet.org</code>.</li>
<li>Qin, S. (2016, March 28). Library of Congress to Replace Term 'Illegal Aliens'. <em>Dartmouth</em>. Retrieved from www.thedartmouth.com.</li>
<li>Rifkin, J. (1995). <em>The End of Work: The Decline of the Global Labor Force and the Dawn of the Post-Market Era</em>. New York: Putnam.</li>
<li>Ritzer, G., and Jurgenson. N. (2010). Production, Consumption, Prosumption. <em>Journal of Consumer Culture</em>, 10(1), 13–36. <code>doi:10.1177/1469540509354673</code>.</li>
<li>Rudman, L. A., and Borgida, E. (1995). The Afterglow of Construct Accessibility: The Behavioral Consequences of Priming Men to View Women as Sexual Objects. <em>Journal of Experimental Social Psychology</em>, 31, 493–517.</li>
<li>Segev, E. (2010). <em>Google and the Digital Divide: The Bias of Online Knowledge</em>. Oxford, UK: Chandos.</li>
<li>Sinclair, B. (2004). Integrating the Histories of Race and Technology. In B. Sinclair (Ed.), <em>Technology and the African American Experience: Needs and Opportunities for Study</em>, 1–17. Cambridge, MA: MIT Press.</li>
<li>Stroman, C. A., Merrit, B. D., and Matabane, P. W. (1989). Twenty Years after Kerner: The Portrayal of African Americans on Prime-Time Television. <em>Howard Journal of Communication</em>, 2, 44–56.</li>
<li>Tapscott, D. (1996). <em>The Digital Economy: Promise and Peril in the Age of Networked Intelligence</em>. New York: McGraw-Hill.</li>
<li>Tettegah, S. Y. (2016). The Good, the Bad, and the Ugly: Color- Blind Racial Ideology. In H. A. Neville, M. E. Gallardo, and D. W. Sue (Eds.), <em>The Myth of Racial Color Blindness: Manifestations, Dynamics, and Impact</em>, 175–190. Washington, DC: American Psychological Association.</li>
<li>Toffler, A. (1970). <em>Future Shock</em>. New York: Random House.</li>
<li>Toffler, A. (1980). <em>The Third Wave</em>. New York: Morrow.</li>
<li>Tippman, S. (2015, July 14). Google Accidentally Reveals Data on &quot;Right to Be Forgotten&quot; Requests. <em>Guardian</em>. Retrieved from <code>www.theguardian.com</code>.</li>
<li>Treitler, V. (2013). <em>The Ethnic Project: Transforming Racial Fiction into Ethnic Factions</em>. Stanford, CA: Stanford University Press.</li>
<li>U.S. Census Bureau. (2008). Table B-2: Poverty Status of People by Age, Race, and Hispanic Origin: 1959– 2008. In <em>Income, Poverty, and Health Insurance Coverage in the United States: 2008</em>, Report P60–236, 50–55. Washington, DC: U.S. Census Bureau.</li>
<li>U.S. Department of Justice, Federal Bureau of Investigation. (2010). Table 43: Arrests, by Race, 2010. In <em>Crime in the United States: 2010</em>. Retrieved from <code>http://ucr.fbi.gov/crime-in-the-u.s/2010/crime-in-the-u.s.-2010/tables/table-43</code>.</li>
<li>Vaidhyanathan, S. (2011). <em>The Googlization of Everything (and Why We Should Worry)</em>. Berkeley: University of California Press.</li>
<li>Wallace, M. (1990). <em>Invisibility Blues: From Pop to Theory</em>. London: Verso.</li>
<li>Warf, B., and Grimes, J. (1997). Counterhegemonic Discourses and the Internet. <em>Geographical Review</em>, 87(2), 259–274.</li>
<li>Wasson, H. (1973). The Ms. in Magazine Advertising. In R. King (Ed.), <em>Proceedings: Southern Marketing Association 1973 Conference</em>, 240– 243. Blacksburg: Virginia Polytechnic Institute and State University.</li>
<li>West, C. (1996). Black Strivings in a Twilight Civilization. In H. L. Gates Jr. and C. West, <em>The Future of the Race</em>, 53–114. New York: Knopf.</li>
<li>West, C. M. (1995). Mammy, Sapphire, and Jezebel: Historical Images of Black Women and Their Implications for Psychotherapy. <em>Psychotherapy</em>, 32(3), 458–466.</li>
<li>White, D. G. (1985/1999). <em>Ar'n't I a Woman? Female Slaves in the Plantation South</em>. New York: Norton.</li>
<li>Williamson, Z. (2014, July 19). Porn SEO. Zack Williamson's blog. Retrieved from <code>www.zackwilliamson.com</code>.</li>
<li>Wilson, P. (1968). <em>Two Kinds of Power: An Essay on Bibliographical Control</em>. Berkeley: University of California Press.</li>
<li>Yang, J. L., and Easton, N. (2009, July 26). Obama &amp; Google (a Love Story). <em>Fortune</em>. Retrieved from <code>http://money.cnn.com</code>.</li>
<li>Yarbrough, M., and Bennett, C. (2000). Cassandra and the &quot;Sistahs&quot;: The Peculiar Treatment of African American Women in the Myth of Women as Liars. <em>Journal of Gender, Race, and Justice</em>, 3(2), 626–657.</li>
<li>Zittrain, J., and Edelman, B. (2002). Localized Google Search Result Exclusions: Statement of Issues and Call for Data. Retrieved from <code>http://cyber.harvard.edu/filtering/google/</code>.</li>
</ul>
<p>dd
<div class="footnotes">
<hr />
<ol>
<li id="fn1">See Dewey, 2015<a href="#fnref1">↩</a></li>
<li id="fn2">I use phrases such as &quot;the N-word&quot; or &quot;n*gger&quot; rather than explicitly using the spelling of a racial epithet in my scholarship. As a regular practice, I also do not cite or promote non-African American scholars or research that flagrantly uses the racial epithet in lieu of alternative phrasings.<a href="#fnref2">↩</a></li>
<li id="fn3">See Olson, 1998; Berman, 1971; Wilson, 1968; and Furner, 2007.<a href="#fnref3">↩</a></li>
<li id="fn4">See chapter 2 for a detailed discussion of the &quot;Jewish&quot; disclaimer by Google.<a href="#fnref4">↩</a></li>
<li id="fn5">See Wasson, 1973; Courtney and Whipple, 1983.<a href="#fnref5">↩</a></li>
<li id="fn6">See Hindman, 2009; Zittrain, 2008; Vaidhyanathan, 2011.<a href="#fnref6">↩</a></li>
<li id="fn7">See Gulli and Signorini, 2005.<a href="#fnref7">↩</a></li>
<li id="fn8">See Fallows, 2005; Purcell, Brenner, and Rainie, 2012.<a href="#fnref8">↩</a></li>
<li id="fn9">See Epstein and Robertson, 2015.<a href="#fnref9">↩</a></li>
<li id="fn10">See Corea, 1993; Dates, 1990; Mastro and Tropp, 2004; Stroman, Merrit, and Ma- tabane, 1989.<a href="#fnref10">↩</a></li>
<li id="fn11">The Federal Trade Commission is looking into the privacy issues facing Americans over Google's targeted and behavior-based advertising programs. It has also settled out of court over the Google book- digitization project, which was reported in the media as a &quot;monopolistic online land grab&quot; over public domain orphan works. See Yang and Easton, 2009.<a href="#fnref11">↩</a></li>
<li id="fn12">See Heider and Harp, 2002.<a href="#fnref12">↩</a></li>
<li id="fn13">Berger, 1972, 64.<a href="#fnref13">↩</a></li>
<li id="fn14">Barzilai-Nahon, 2006.<a href="#fnref14">↩</a></li>
<li id="fn15">See Williamson, 2014.<a href="#fnref15">↩</a></li>
<li id="fn16">See C. M. West, 1995; hooks, 1992.<a href="#fnref16">↩</a></li>
<li id="fn17">See Ladson-Billings, 2009.<a href="#fnref17">↩</a></li>
<li id="fn18">See Yarbrough and Bennett, 2000.<a href="#fnref18">↩</a></li>
<li id="fn19">See Treitler, 2013; Bell, 1992; Delgado and Stefancic, 1999.<a href="#fnref19">↩</a></li>
<li id="fn20">Warf and Grimes, 1997, 260.<a href="#fnref20">↩</a></li>
<li id="fn21">Brock, 2011, 1088.<a href="#fnref21">↩</a></li>
<li id="fn22">See Davis, 1972.<a href="#fnref22">↩</a></li>
<li id="fn23">U.S. Census Bureau, 2008.<a href="#fnref23">↩</a></li>
<li id="fn24">See White, (1985) 1999.<a href="#fnref24">↩</a></li>
<li id="fn25">See Miller-Young, 2005; Harris-Perry, 2011.<a href="#fnref25">↩</a></li>
<li id="fn26">See White, 1985/1999, 29. White's book is an excellent historical examination of the Jezebel portrayal, especially chapter 1, &quot;Jezebel and Mammy&quot; (27– 61).<a href="#fnref26">↩</a></li>
<li id="fn27">See C. M. West, 1995.<a href="#fnref27">↩</a></li>
<li id="fn28">See Paasonen, 2011.<a href="#fnref28">↩</a></li>
<li id="fn29">Paasonen, 2010, 418.<a href="#fnref29">↩</a></li>
<li id="fn30">Ibid<a href="#fnref30">↩</a></li>
<li id="fn31">Dines, 2010, 48.<a href="#fnref31">↩</a></li>
<li id="fn32">See Rudman and Borgida, 1995; Kenrick, Gutierres, and Goldberg, 1989; Jennings, Geis, and Brown, 1980.<a href="#fnref32">↩</a></li>
<li id="fn33">FBI statistics from 2010 show that the majority of crime happens within race. They also note that &quot;White individuals were arrested more often for violent crimes than individuals of any other race, accounting for 59.3 percent of those arrests.&quot; See U.S. Department of Justice, 2010.<a href="#fnref33">↩</a></li>
<li id="fn34">Tippman, 2015.<a href="#fnref34">↩</a></li>
<li id="fn35">Qin, 2016.<a href="#fnref35">↩</a></li>
<li id="fn36">See Berman, 1971; Olson, 1998.<a href="#fnref36">↩</a></li>
<li id="fn37">See C. West, 1996, 84.<a href="#fnref37">↩</a></li>
<li id="fn38">Cohen, 2016.<a href="#fnref38">↩</a></li>
<li id="fn39">See Harris-Perry, 2011; hooks, 1992.<a href="#fnref39">↩</a></li>
<li id="fn40">Ingram, 2011.<a href="#fnref40">↩</a></li>
<li id="fn41">See Sinclair, 2004.<a href="#fnref41">↩</a></li>
<li id="fn42">See Segev, 2010.<a href="#fnref42">↩</a></li>
<li id="fn43">See Rifkin, 1995.<a href="#fnref43">↩</a></li>
<li id="fn44">The term &quot;prosumer&quot; is a portmanteau of &quot;producer&quot; and &quot;consumer&quot; that is often used to indicate a higher degree of digital literacy, economic participation, and personal control over the means of technology production. The term is mostly attributed, in this context, to Alvin Toffler, a futurist who thought that the line between traditional economic consumer and producer would eventually blur through engagements with technology and that this participation would generally lead to greater mass customization of products and services by corporations. See Toffler, 1970, 1980; Tapscott, 1996; Ritzer and Jurgenson, 2010.<a href="#fnref44">↩</a></li>
<li id="fn45">See Meyer, 2016.<a href="#fnref45">↩</a></li>
<li id="fn46">See Glusac, 2016.<a href="#fnref46">↩</a></li>
<li id="fn47">See Eddie and Prigg, 2015.<a href="#fnref47">↩</a></li>
<li id="fn48">See Mosher, 2016.<a href="#fnref48">↩</a></li>
<li id="fn49">Wallace, 1990, 98.<a href="#fnref49">↩</a></li>
<li id="fn50">See Jensen, 2005; Brown, 2003; Burdman, 2008.<a href="#fnref50">↩</a></li>
<li id="fn51">See Neville et al., 2012.<a href="#fnref51">↩</a></li>
<li id="fn52">See Pawley, 2006.<a href="#fnref52">↩</a></li>
<li id="fn53">See Tettegah, 2016.<a href="#fnref53">↩</a></li>
<li id="fn54">See Brown, 2003; Crenshaw, 1991.<a href="#fnref54">↩</a></li>
<li id="fn55">See Brown, 2003.<a href="#fnref55">↩</a></li>
<li id="fn56">Ibid.<a href="#fnref56">↩</a></li>
<li id="fn57">See Daniels, 2008.<a href="#fnref57">↩</a></li>
</ol>
</div>
</body>
</html>
</body>
</html>
